{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image list from /Users/prachit/self/[0]Working/OCT/noise2noise/img1\n",
      "\n",
      "Debug: Scanning directory structure of /Users/prachit/self/[0]Working/OCT/noise2noise/img1\n",
      "Found files and directories:\n",
      "img1/\n",
      "  Frame5.png\n",
      "  Frame4.png\n",
      "  Frame3.png\n",
      "  Frame2.png\n",
      "  Frame1.png\n",
      "\n",
      "Found 5 total images\n",
      "\n",
      "First 5 images found:\n",
      "  /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame1.png\n",
      "  /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame2.png\n",
      "  /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame3.png\n",
      "  /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame4.png\n",
      "  /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame5.png\n",
      "0 /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame1.png\n",
      "/Users/prachit/self/[0]Working/OCT/noise2noise/dataset_tool_tf.py:122: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  'data': bytes_feature(tf.compat.as_bytes(image.tostring()))\n",
      "1 /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame2.png\n",
      "2 /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame3.png\n",
      "3 /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame4.png\n",
      "4 /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame5.png\n",
      "Dataset statistics:\n",
      "  Formats:\n",
      "    L: 5 images\n",
      "  width,height buckets:\n",
      "    >= 256x256: 5 images\n"
     ]
    }
   ],
   "source": [
    "# This should run through roughly 50K images and output a file called `datasets/imagenet_val_raw.tfrecords`.\n",
    "!python dataset_tool_tf.py --input-dir \"/Users/prachit/self/[0]Working/OCT/noise2noise/img1/\" --out=datasets/imagenet_val_raw.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iteration_count': 500000, 'eval_interval': 5000, 'minibatch_size': 4, 'run_func_name': 'train.train', 'learning_rate': 0.0003, 'ramp_down_perc': 0.5, 'noise': {'func_name': 'train.AugmentGaussian', 'train_stddev_rng_range': (0.0, 50.0), 'validation_stddev': 25.0}, 'noise2noise': True, 'train_tfrecords': '/Users/prachit/self/[0]Working/OCT/noise2noise/datasets/imagenet_val_raw.tfrecords', 'validation_config': {'dataset_dir': '/Users/prachit/self/[0]Working/OCT/noise2noise/img1'}}\n",
      "Creating the run dir: /Users/prachit/self/[0]Working/OCT/noise2noise/results/00011-autoencoder-test-n2n\n",
      "Copying files to the run dir\n",
      "dnnlib: Running train.train() on localhost...\n",
      "Loading validation images from: /Users/prachit/self/[0]Working/OCT/noise2noise/img1\n",
      "\n",
      "Directory contents:\n",
      "  Frame5.png\n",
      "  Frame4.png\n",
      "  Frame3.png\n",
      "  Frame2.png\n",
      "  Frame1.png\n",
      "Found image: /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame5.png\n",
      "Found image: /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame4.png\n",
      "Found image: /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame3.png\n",
      "Found image: /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame2.png\n",
      "Found image: /Users/prachit/self/[0]Working/OCT/noise2noise/img1/Frame1.png\n",
      "\n",
      "Loading 5 validation images...\n",
      "Successfully loaded: Frame1.png\n",
      "Successfully loaded: Frame2.png\n",
      "Successfully loaded: Frame3.png\n",
      "Successfully loaded: Frame4.png\n",
      "Successfully loaded: Frame5.png\n",
      "\n",
      "Successfully loaded 5 validation images\n",
      "2025-01-18 18:17:05.799071: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-01-18 18:17:05.799092: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-01-18 18:17:05.799097: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-01-18 18:17:05.799113: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-18 18:17:05.799124: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Setting up dataset source from /Users/prachit/self/[0]Working/OCT/noise2noise/datasets/imagenet_val_raw.tfrecords\n",
      "2025-01-18 18:17:08.363275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "Average PSNR: 8.52\n"
     ]
    }
   ],
   "source": [
    "!python config.py --desc='-test' train --train-tfrecords=datasets/imagenet_val_raw.tfrecords --long-train=true --noise=gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
